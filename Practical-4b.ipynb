{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hrk84ya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/hrk84ya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"\"\"Natural Language Processing (NLP) is a subfield of artificial intelligence that focuses on the interaction between computers and humans using natural language. It involves the development of algorithms and models\n",
    "that enables machines to understand, interpret, and generate human-like text. NLP plays a crucial role in various applications, including sentiment analysis, machine translation, chatbots, and information extraction.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens= word_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_tokens=[lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural -> Natural\n",
      "Language -> Language\n",
      "Processing -> Processing\n",
      "( -> (\n",
      "NLP -> NLP\n",
      ") -> )\n",
      "is -> is\n",
      "a -> a\n",
      "subfield -> subfield\n",
      "of -> of\n",
      "artificial -> artificial\n",
      "intelligence -> intelligence\n",
      "that -> that\n",
      "focuses -> focus\n",
      "on -> on\n",
      "the -> the\n",
      "interaction -> interaction\n",
      "between -> between\n",
      "computers -> computer\n",
      "and -> and\n",
      "humans -> human\n",
      "using -> using\n",
      "natural -> natural\n",
      "language -> language\n",
      ". -> .\n",
      "It -> It\n",
      "involves -> involves\n",
      "the -> the\n",
      "development -> development\n",
      "of -> of\n",
      "algorithms -> algorithm\n",
      "and -> and\n",
      "models -> model\n",
      "that -> that\n",
      "enables -> enables\n",
      "machines -> machine\n",
      "to -> to\n",
      "understand -> understand\n",
      ", -> ,\n",
      "interpret -> interpret\n",
      ", -> ,\n",
      "and -> and\n",
      "generate -> generate\n",
      "human-like -> human-like\n",
      "text -> text\n",
      ". -> .\n",
      "NLP -> NLP\n",
      "plays -> play\n",
      "a -> a\n",
      "crucial -> crucial\n",
      "role -> role\n",
      "in -> in\n",
      "various -> various\n",
      "applications -> application\n",
      ", -> ,\n",
      "including -> including\n",
      "sentiment -> sentiment\n",
      "analysis -> analysis\n",
      ", -> ,\n",
      "machine -> machine\n",
      "translation -> translation\n",
      ", -> ,\n",
      "chatbots -> chatbots\n",
      ", -> ,\n",
      "and -> and\n",
      "information -> information\n",
      "extraction -> extraction\n",
      ". -> .\n"
     ]
    }
   ],
   "source": [
    "# display original and lemmatized words\n",
    "for original, lemmatized in zip(tokens,lemmatized_tokens):\n",
    "    print(f\"{original} -> {lemmatized}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q. Why is this method not removing -ing from the text?\n",
    "### Ans: By default, lemmatizer.lemmatize(token) assumes that every word is a noun unless you specify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
